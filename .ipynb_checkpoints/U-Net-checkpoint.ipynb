{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adam', 'BatchNormalization', 'Conv2D', 'Cropping2D', 'FeatureExtractor', 'Input', 'K', 'Lambda', 'MaxPooling2D', 'Model', 'ModelCheckpoint', 'Reshape', 'Undistorter', 'UpSampling2D', 'VideoFileClip', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'apply_threshold', 'bg', 'car_detection', 'clips_array', 'concatenate', 'cv2', 'dice_coef', 'dice_coef_loss', 'draw_labeled_bboxes', 'extract_hog_features', 'feature_extractor', 'fun', 'generate_heatmap', 'generate_heatmaps', 'get_hog_features', 'get_model', 'hog', 'hog_extractor', 'img_cols', 'img_rows', 'isfile', 'joblib', 'join', 'listdir', 'log_progress', 'math', 'multiprocessing', 'np', 'parmap', 'quickpool', 'sliding_window', 'smooth', 'undistorter', 'unet']\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "%aimport -plt\n",
    "%aimport -np\n",
    "%aimport -glob\n",
    "%aimport -cv2\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "%matplotlib inline\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "nb_dir = os.getcwd()\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "import car_detection\n",
    "print(dir(car_detection))\n",
    "from car_detection import log_progress\n",
    "import builtins\n",
    "from IPython.lib import deepreload\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "import sklearn\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import car_detection\n",
    "import sys\n",
    "sys.stdout.isatty()\n",
    "from car_detection import log_progress\n",
    "\n",
    "def show_image(img, title=''):\n",
    "    fig = plt.figure(figsize=(10,100))\n",
    "    plt.imshow(img)\n",
    "    fig.suptitle(title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import CrowdAI dataset\n",
    "my_path = 'D:\\\\vehicle_detection\\\\object-detection-crowdai'\n",
    "bounding_boxs = {}\n",
    "labels = [label for label in csv.DictReader(open(my_path + '\\\\labels.csv','r')) if label['Label'] != 'Pedestrian']\n",
    "\n",
    "for label in labels:\n",
    "    file_name = label['Frame']\n",
    "    current_bounding_boxs = bounding_boxs.get(file_name, [])\n",
    "    label = {\n",
    "        'xmin': int(label['xmin']),\n",
    "        'xmax': int(label['ymin']),\n",
    "        'ymin': int(label['xmax']),\n",
    "        'ymax': int(label['ymax'])    \n",
    "    }\n",
    "    current_bounding_boxs.append(label)\n",
    "    bounding_boxs[file_name] = current_bounding_boxs\n",
    "    \n",
    "onlyfiles = [f for f in listdir(my_path) if isfile(join(my_path, f)) and f[-4:] == '.jpg']\n",
    "    \n",
    "for file_name in onlyfiles:\n",
    "    boxes = bounding_boxs.get(file_name,[])\n",
    "    if len(boxes) > 0:    \n",
    "        dataset.append({\n",
    "            'path': my_path + '\\\\' + file_name,\n",
    "            'boxes': bounding_boxs.get(file_name,[])\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import other dataset\n",
    "my_path = 'D:\\\\vehicle_detection\\\\object-detection'\n",
    "bounding_boxs = {}\n",
    "fields = ['frame', 'xmin', 'ymin', 'xmax', 'ymax', 'occluded', 'label']\n",
    "reader = csv.DictReader(open(my_path + '\\\\labels.csv','r'), delimiter=' ', fieldnames =fields)\n",
    "\n",
    "labels = [label for label in reader if label['label'] in ['car', 'truck']]\n",
    "\n",
    "for label in labels:\n",
    "    file_name = label['frame']\n",
    "    current_bounding_boxs = bounding_boxs.get(file_name, [])\n",
    "    label = {\n",
    "        'xmin': int(label['xmin']),\n",
    "        'xmax': int(label['xmax']),\n",
    "        'ymin': int(label['ymin']),\n",
    "        'ymax': int(label['ymax'])    \n",
    "    }\n",
    "    current_bounding_boxs.append(label)\n",
    "    bounding_boxs[file_name] = current_bounding_boxs\n",
    "    \n",
    "onlyfiles = [f for f in listdir(my_path) if isfile(join(my_path, f)) and f[-4:] == '.jpg']\n",
    "    \n",
    "for file_name in onlyfiles:\n",
    "    boxes = bounding_boxs.get(file_name,[])\n",
    "    if len(boxes) > 0:    \n",
    "        dataset.append({\n",
    "            'path': my_path + '\\\\' + file_name,\n",
    "            'boxes': bounding_boxs.get(file_name,[])\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_pic(path, scale=1):\n",
    "    img = cv2.imread(path)\n",
    "    if scale != 1:\n",
    "        new_shape = (int(img.shape[1] * scale), int(img.shape[0] * scale))\n",
    "        img = cv2.resize(img, new_shape)\n",
    "    if img is not None:\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return None\n",
    "\n",
    "def build_mask(bounding_boxs,size=(1200.0,1920.0), scale=1.0):\n",
    "    mask = np.zeros((int(size[0]*scale), int(size[1]*scale)), dtype=np.uint8)\n",
    "    for box in bounding_boxs:\n",
    "        xmin = int(box['xmin'] * scale)\n",
    "        xmax = int(box['xmax'] * scale)\n",
    "        ymin = int(box['ymin'] * scale)\n",
    "        ymax = int(box['ymax'] * scale)       \n",
    "        mask[ymin:ymax,xmin:xmax] = 1\n",
    "    return mask\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "\n",
    "    `initial_img` should be the image before any processing.\n",
    "\n",
    "    The result image is computed as follows:\n",
    "\n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "mask = build_mask(dataset[100]['boxes'], scale=0.5)\n",
    "pic = load_pic(dataset[100]['path'], scale=0.5)\n",
    "show_image(pic)\n",
    "show_image(mask)\n",
    "show_image(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 600, 960, 3)\n",
      "(?, 600, 960, 32)\n",
      "(?, 300, 480, 32)\n",
      "(?, 150, 240, 64)\n",
      "(?, 75, 120, 128)\n",
      "(?, 38, 60, 256)\n",
      "(?, 600, 960, 1)\n",
      "(?, 600, 960)\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "import car_detection\n",
    "model = car_detection.get_model()\n",
    "model.load_weights(\"./tmp/weights__3.14--0.78.hdf5\")\n",
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "dataset = shuffle(dataset)\n",
    "training_set, test_set = train_test_split(dataset, test_size=0.3)\n",
    "training_set, validation_set = train_test_split(training_set, test_size=0.1)\n",
    "#training_set = training_set[0:10]\n",
    "#validation_set = validation_set[0:50]\n",
    "def myGenerator(dataset):\n",
    "    #loading data\n",
    "    while True:\n",
    "        for i in range(len(dataset)):\n",
    "            pic = load_pic(dataset[i]['path'], scale=0.5)\n",
    "            \n",
    "            mask = build_mask(dataset[i]['boxes'], scale=0.5)\n",
    "            result = [np.array([pic]), np.array([mask])]\n",
    "\n",
    "            yield result\n",
    "training_generator = myGenerator(training_set)\n",
    "validating_generator = myGenerator(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath=\"./tmp/weights__3.{epoch:02d}-{val_loss:.2f}.hdf5\", verbose=1)\n",
    "model.fit_generator(training_generator, \n",
    "                    steps_per_epoch=len(training_set), \n",
    "                    epochs=15, \n",
    "                    verbose=0,\n",
    "                    validation_data=validating_generator, \n",
    "                    validation_steps=len(validation_set), \n",
    "                    callbacks=[checkpointer,TQDMNotebookCallback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "show_image(build_mask(test_set[0]['boxes'], scale=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "datapoint = test_set[11]\n",
    "test_pic = load_pic(datapoint['path'], scale=0.5)\n",
    "prediction = model.predict(np.array([test_pic]))[0]\n",
    "mask = build_mask(datapoint['boxes'], scale=0.5)\n",
    "show_image(test_pic)\n",
    "show_image(mask)\n",
    "show_image(prediction)\n",
    "\n",
    "print(car_detection.loss_function(mask, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "heatmaps = []\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    bboxes = []\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), \n",
    "                 np.max(nonzerox) - np.min(nonzerox),\n",
    "                 np.max(nonzeroy) - np.min(nonzeroy))\n",
    "        bbox = cv2.rectangle(np.min(nonzerox), np.min(nonzeroy), \n",
    "                 np.max(nonzerox) - np.min(nonzerox),\n",
    "                 np.max(nonzeroy) - np.min(nonzeroy))\n",
    "        bboxes.append(bbox)\n",
    "    \n",
    "    bboxes = cv2.groupRectangles(list(bboxes),1)\n",
    "        \n",
    "        \n",
    "    for bbox in bboxes:#combine_rectangles(bboxes):\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def point_in_rectangle(rectangle, point):\n",
    "    #Rectangle should be two points\n",
    "\n",
    "    if rectangle[0][0] < point[0] and point[0] < rectangle[1][0]:\n",
    "        if rectangle[0][1] < point[1] and point[1] < rectangle[1][1]:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def in_other_rect(rect_inner,rect_outer):\n",
    "    points = [\n",
    "        rect_outer[0],\n",
    "        rect_outer[1],\n",
    "        (rect_outer[1][0], rect_outer[0][1]),\n",
    "        (rect_outer[0][1], rect_outer[1][1])\n",
    "    ]\n",
    "    for point in points:\n",
    "        if point_in_rectangle(rect_inner, point):\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "def combine_rectangles(rects): \n",
    "    outer_rects=[rects[:]]\n",
    "    for rect_inner in rects:\n",
    "        for rect_outer in rects:\n",
    "            if(in_other_rect(rect_inner,rect_outer)):\n",
    "                if rect_inner in outer_rects:\n",
    "                    outer_rects.remove(rect_inner)\n",
    "    return outer_rects[0]\n",
    "\n",
    "def get_find_cars_func(heatmap_shortcircuit=False, raw_shortcircuit=False):\n",
    "    def find_cars_func(img):\n",
    "        global heatmaps\n",
    "        img = cv2.resize(img,(960, 600), interpolation = cv2.INTER_CUBIC)\n",
    "        draw_img = img.copy()\n",
    "        heatmap = model.predict(np.array([draw_img]))[0]\n",
    "        \n",
    "        if heatmap_shortcircuit == True:\n",
    "            print(heatmap.shape)\n",
    "            output = np.stack((heatmap*255,heatmap*255,heatmap*255),axis=2)\n",
    "            print(output.shape)\n",
    "            return output\n",
    "        heatmaps.append(heatmap * 30)\n",
    "        heatmap = np.array(np.mean(heatmaps, axis=(0)), dtype=np.uint8)\n",
    "        #heatmap = np.mean(heatmaps).astype(np.int32)\n",
    "        heatmaps = heatmaps[-10:]\n",
    "        heatmap = apply_threshold(heatmap, 25)\n",
    "        labels = label(heatmap)\n",
    "        \n",
    "        if raw_shortcircuit == True:\n",
    "            hm = heatmap*(255/np.max(heatmap))\n",
    "            hm = np.stack((hm,hm,hm),axis=2)\n",
    "            return draw_labeled_bboxes(hm, labels)\n",
    "        return draw_labeled_bboxes(draw_img, labels)\n",
    "    return find_cars_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./project_video.mp4\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 6] The handle is invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-88f87b930ed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mrun_test_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-88f87b930ed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#run_video(input, output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mrun_test_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-88f87b930ed5>\u001b[0m in \u001b[0;36mrun_test_video\u001b[1;34m(input, output)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mfind_cars_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_find_cars_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mclip1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.subclip(30.0,33.0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mresult_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_cars_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time result_clip.write_videofile(output, audio=False)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, has_mask, audio, audio_buffersize, audio_fps, audio_nbytes, verbose)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Make a reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mpix_fmt\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"rgba\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhas_mask\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"rgb24\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFFMPEG_VideoReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpix_fmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpix_fmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# Make some of the reader's attributes accessible from the clip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mffmpeg_parse_infos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_infos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_duration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'video_fps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'video_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py\u001b[0m in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mpopen_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"creationflags\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0x08000000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpopen_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    843\u001b[0m                  pass_fds=()):\n\u001b[0;32m    844\u001b[0m         \u001b[1;34m\"\"\"Create new Popen instance.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    846\u001b[0m         \u001b[1;31m# Held while anything is calling waitpid before returncode has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[1;31m# updated to prevent clobbering returncode if wait() or poll() are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_cleanup\u001b[1;34m()\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_active\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_deadstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_internal_poll\u001b[1;34m(self, _deadstate, _WaitForSingleObject, _WAIT_OBJECT_0, _GetExitCodeProcess)\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \"\"\"\n\u001b[0;32m   1254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0m_WaitForSingleObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_WAIT_OBJECT_0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_GetExitCodeProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 6] The handle is invalid"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, clips_array\n",
    "\n",
    "def run_video(input, output):\n",
    "    print(input)\n",
    "    find_cars_func = get_find_cars_func(heatmap_shortcircuit=True)\n",
    "    clip1 = VideoFileClip(input)\n",
    "    result_clip = clip1.fl_image(find_cars_func)\n",
    "    %time result_clip.write_videofile(output, audio=False)\n",
    "    del result_clip\n",
    "\n",
    "    find_cars_func = get_find_cars_func(heatmap_shortcircuit=False)\n",
    "    clip1 = VideoFileClip(input)\n",
    "    result_clip = clip1.fl_image(find_cars_func)\n",
    "    %time result_clip.write_videofile(\"otherone_{0}\".format(output), audio=False)\n",
    "    del result_clip\n",
    "    \n",
    "def run_test_video(input, output):\n",
    "    print(input)\n",
    "    find_cars_func = get_find_cars_func()\n",
    "    clip1 = VideoFileClip(input)#.subclip(30.0,33.0)\n",
    "    result_clip = clip1.fl_image(find_cars_func)\n",
    "    %time result_clip.write_videofile(output, audio=False)\n",
    "    del result_clip\n",
    "    \n",
    "input = './project_video.mp4'\n",
    "output = './project_video_outcome.mp4'\n",
    "try:\n",
    "    #run_video(input, output)\n",
    "    run_test_video(input, output)\n",
    "except Exception as e: \n",
    "    raise e"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
